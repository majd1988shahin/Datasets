# -*- coding: utf-8 -*-
"""labor07_Unet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jnd0WBy08nw6T1SDvqupHykQqyTOfivd
"""

import keras
import numpy as np
import sys
import cv2
class Generator(keras.utils.Sequence):
    def __init__(self, x_folder,y_folder,batchsize,scale=1/255,perfex="",sufx=".png",start=0,end=None,patchVisal=False):
        self.x,self.y=x_folder,y_folder
        self.batchsize=batchsize
        self.scale=scale
        self.sufx,self.perfex=sufx,perfex
        self.start=start
        
        self.samples_num=self.get_samples_num()
        if self.samples_num==0:
          
          raise Exception("Kein Datei darin!")
        self.end=self.samples_num+self.start if end==None else end
        self.patchVisal=patchVisal
        super().__init__()
    
    def names_gen(self,folder,start_id=None):
      i=self.start if start_id==None else start_id
      while True:
        name= folder+self.perfex+str(i)+self.sufx
        #print(name)
        yield name
        i+=1

    def get_samples_num(self):
      import os
      xn=0
      x_name_gen=self.names_gen(self.x)
      while True:
        name=next(x_name_gen)
        if not os.path.isfile(name): break
        xn+=1

      yn=0
      y_name_gen=self.names_gen(self.y)
      while True:
        name=next(y_name_gen)
        if not os.path.isfile(name): break
        yn+=1
      
      return min(xn,yn)
        

    def __len__(self):
        return self.samples_num//self.batchsize#int(np.ceil(len(self.x) / float(self.batch_size)))
    def __getitem__(self,idx):
        x=[]
        y=[]
        try:
            current_idx=idx*self.batchsize+self.start
            end= min(current_idx+self.batchsize,self.end)
            x_names=self.names_gen(self.x,current_idx)
            y_names=self.names_gen(self.y,current_idx)
            for i in range(current_idx,end):
                x_n=next(x_names)
                #print("reading ",x_n)
                x.append(cv2.imread(x_n).astype(float)*self.scale)
                y.append(cv2.imread(next(y_names)).astype(float))
                #print(x[0].shape)
        except IndexError:
            print("IndexError",i)
        X,Y= np.array(x) , np.array(y)
        if self.patchVisal :print("\nPatch ",X.shape)
        #X,Y=X.astype(float)/self.scale ,Y.astype(float)/self.scale
        return X,Y

import sys, os 
from google.colab import drive

drive.mount("/content/drive")

!ls
os.chdir("drive/My Drive/PYP")

import os, psutil,gc, numpy as np
gc.collect()

ls

import cv2
a=cv2.imread("Datasets/images32X32X3/0.png")
b=cv2.imread("Datasets/Masks/55.png")
print(a.shape,a.max(),a.dtype)
print(b.shape,b.max(),b.dtype)
print((b[:,:,0]==b[:,:,1]).all(),(b[:,:,2]==b[:,:,1]).all())

!cat Generator.py

from keras.layers import BatchNormalization, Activation, Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, concatenate
from keras.models import Model
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam
import matplotlib.pyplot as plt
import numpy as np

ops=[{"i":"Datasets/images/","o":"Datasets/images32X32X3/","n":633,"norm":False}]
ops.append({"i":"Datasets/imagesValidation/","o":"Datasets/imagesValidation32X32X3/","n":65,"norm":False})
ops.append({"i":"Datasets/Masks/","o":"Datasets/Masks_32X32x3/","n":633,"norm":True})
ops.append({"i":"Datasets/MasksValidation/","o":"Datasets/MasksValidation_32X32X3/","n":65,"norm":True})

sufex=".png"
for p in ops:
  try:os.mkdir(p["o"])
  except: pass
  for i in range(p["n"]):
    iName=p["i"]+str(i)+sufex
    a=cv2.imread(iName)
    print(p)
    print(i)
    b=cv2.resize(a,dsize=(32,32))
    if p["norm"]:
      b=b/a.max()
    oName=p["o"]+str(i)+sufex
    cv2.imwrite(oName,b)

def Unet():
  inputs = Input((32,32,3))   #(32, 32, 3))
  conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
  conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)
  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
  conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)
  conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)
  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
  conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
  conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
  conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)
  conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)
  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)
  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)
  up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=-1)
  conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)
  conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)
  up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=-1)
  conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)
  conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)
  up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=-1)
  conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)
  conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)
  up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=-1)

  conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)
  conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)
  conv10 = Conv2D(3, (3, 3), activation='softmax', padding='same')(conv9)

  model = Model(inputs=inputs, outputs=conv10)
  return model



model.summary()

gt=Generator(ops[0]["o"],ops[2]["o"],11)
gv=Generator(ops[1]["o"],ops[3]["o"],11)
x,y=gt.__getitem__(0)
plt.figure(0);plt.imshow(x[2])
plt.figure(1);plt.imshow(y[2])
print("x",x[0].max(),x.shape,x[0].dtype)
print("y",y[0].max(),y.shape,y[0].dtype)

gt=Generator(ops[0]["o"],ops[2]["o"],16)
gv=Generator(ops[1]["o"],ops[3]["o"],12)
model=Unet()
#model.compile(optimizer='adam', loss='....')
from keras import optimizers

adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.97, amsgrad=True)

model.compile(optimizer=adam,loss='mean_squared_error',
                  metrics=['accuracy'])
model.fit_generator(gt,40,validation_data=gv,epochs=40)

# load pretrained weights# load p #
saveDir = './'
es_cb = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')